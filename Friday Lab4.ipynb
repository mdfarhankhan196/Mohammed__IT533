{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEEK 5: FRIDAY LAB 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment: The various types of regression we have looked at in this module are everyday methods in a Data Analyst's toolkit. This week, you will determine which of the variables in your team dataset depend on other variables; that is, which independent variables can be used to predict values for the dependent variable most effectively.\n",
    "\n",
    "Complete the analyses below in a .ipynb file and answer the following questions in markdown (.ipnyb) (1 point each):\n",
    "1. Select one dependent variable in the dataset. This will be your target variable for the remainder of this lab. Explain how and why you have selected that particular target variable in no less than 3 sentences.\n",
    "\n",
    "2. Determine what correlations there are among independent variables (= predictors) in the dataset by setting up a correlation table.  Explain in at least 2 sentences what correlations your analysis is showing and if any predictor variables appear to be correlated to one another\n",
    "\n",
    "3. Determine which independent variable in the dataset is the most important overall predictor for your chosen dependent (target) variable, then build a simple linear regression based on this predictor and evaluate the quality of your model. Explain why (or why not) it is acceptable to use this model to predict future values of your dependent variable.\n",
    "\n",
    "4. Run a basic multiple regression and review the p-values for each variable. If any variables have p-values > 0.05, remove them because they are not statistically significant. Rerun the multiple regression until you can see which of the variables in your dataset should be combined to produce an optimal model. Then build and run your multiple regression model and test its quality. Explain how this model improves the output of the simple linear regression you ran previously.\n",
    "\n",
    "5. Transform your dependent variable from question 1 into a binary shape. Build and run a logistic regression model and explain in AT LEAST two sentences how your output improves on the simple and multiple regression. Is the logistic model better or not as good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "#Reading in the Bank Marketing dataset. ,\n",
    "bank = pd.read_csv('https://raw.githubusercontent.com/mdfarhankhan196/Mohammed__IT533/master/data/bank-full.csv', sep=';')\n",
    "#Verifying that we can see the data\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "y            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select one dependent variable in the dataset. This will be your target variable for the remainder of this lab. Explain how and why you have selected that particular target variable in no less than 3 sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected dependant variable is y in the dataset. The variable y shows wheather a client will subscribe a term deposit or not. The prediction of y will help identify clients who are likely to subscribe to a term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine what correlations there are among independent variables (= predictors) in the dataset by setting up a correlation table.  Explain in at least 2 sentences what correlations your analysis is showing and if any predictor variables appear to be correlated to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097783</td>\n",
       "      <td>-0.009120</td>\n",
       "      <td>-0.004648</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>-0.023758</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.097783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>-0.014578</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.016674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.009120</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030206</td>\n",
       "      <td>0.162490</td>\n",
       "      <td>-0.093044</td>\n",
       "      <td>-0.051710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>-0.004648</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>-0.030206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084570</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>0.004760</td>\n",
       "      <td>-0.014578</td>\n",
       "      <td>0.162490</td>\n",
       "      <td>-0.084570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088628</td>\n",
       "      <td>-0.032855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pdays</th>\n",
       "      <td>-0.023758</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>-0.093044</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>-0.088628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>-0.051710</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>-0.032855</td>\n",
       "      <td>0.454820</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age   balance       day  duration  campaign     pdays  previous\n",
       "age       1.000000  0.097783 -0.009120 -0.004648  0.004760 -0.023758  0.001288\n",
       "balance   0.097783  1.000000  0.004503  0.021560 -0.014578  0.003435  0.016674\n",
       "day      -0.009120  0.004503  1.000000 -0.030206  0.162490 -0.093044 -0.051710\n",
       "duration -0.004648  0.021560 -0.030206  1.000000 -0.084570 -0.001565  0.001203\n",
       "campaign  0.004760 -0.014578  0.162490 -0.084570  1.000000 -0.088628 -0.032855\n",
       "pdays    -0.023758  0.003435 -0.093044 -0.001565 -0.088628  1.000000  0.454820\n",
       "previous  0.001288  0.016674 -0.051710  0.001203 -0.032855  0.454820  1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = bank.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous and the pdays have the best positive correlation in the correlation table of predictors. Day and pdays have the best negative correlation in the correlation table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Determine which independent variable in the dataset is the most important overall predictor for your chosen dependent (target) variable, then build a simple linear regression based on this predictor and evaluate the quality of your model. Explain why (or why not) it is acceptable to use this model to predict future values of your dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEmCAYAAACzoiEDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr80lEQVR4nO3debwcVZn/8c83N4GwCQlBJGxhCUsgECAgiMgiKoosKgqoY1CcOAoiw88ZcHAUcRkQFQXcMmxBEJAIEtnDDpFAwpqQEIgBJRFlIOxIILnf3x91Ouk0d+mb7q7q7vu8X6963apTVf2cJuG5J6dOnSPbhBBCKMaAoisQQgj9WSThEEIoUCThEEIoUCThEEIoUCThEEIoUCThEEIoUCThEEIoUCThEEIo0MCiKxBCs5P0HmAEZf+/2L6osAqFthJJOIQeSPoNsAXwELA0FRuIJBzqQvHacgjdkzQHGOX4HyU0SPQJh9CzWcC7iq5EaF/RHRFCz4YBsyXdBywuFdo+uLgqhXYSSTiEnp1SdAVCe4s+4RBCjyQNANa0/XLRdWlH0SccWoKkDSW9R9L7SltOcV+R9HLF9rSkqyRtnkcdiiDpt5LeIWkNsn7x2ZL+o+h6taNoCYemJ+l04HBgNmXDxPLol5X0XWAB8FtAwBFkQ9YeAL5se59G16EIkh6yPUbSZ4CdgZOA+23vUHDV2k4k4dD0JM0FdrC9uNeL6x/7Yds7VpSVEtTbzrULSY8CY8h++Zxj+452/r5Fiu6IFiJpfUnnSbo+HY+SdHTR9crBfGBQQbFfl/QpSQPS9ingjXSunVswvwaeAtYA7pS0KRB9wg0QLeEWkpLvBcDJtneUNBB40PbogqvWUJJ+D+wI3MKKw8SOyyH25sDPgD3Iku404N+BhcAutu9udB2ahaSBtpcUXY92E0m4hUiabntXSQ/a3imVPWR7TMFVayhJ47oqtz0x77r0F5K+1VW57VPzrku7i3HCreU1SeuS/hksaXfgpWKr1Hi2J0paBdgqFc21/VYjY0r6T9s/lHQ2XXQ75NEKL9hrZfuDgY8CcwqqS1uLJNxaTgAmA1tImgqsBxxWbJUaT9I+wESyPkoBG0saZ/vOBoYtJZwZDYzRtGz/uPxY0o+AGwuqTluL7ogWk/qBtyZLRg1vETYDSfcDn7Y9Nx1vBVxqe5dia9Z/SBoCTLe9ZdF1aTfREm4hko4BLrH9aDoeIulI278ouGqNNqiUgAFsPy4pl9ESktYDTgRGkf2zvFSH/fKIXxRJM1neDdNB9q+u6A9ugGgJt5CuHsKVP6RrV5LOBzqBi1PRZ4AO21/IIfZNwOXA14F/A8YB/2f7xEbHLlIaklayBPhHjIxojEjCLSS1TnYozW0rqQN4xPZ2xdassSStChwDvDcV3QX8Io+XNyTdb3sXSY+U3hYrjVJpdOyiSdoR2Csd3mn7kSLr066iO6K13ABcLunX6fhLqaytpWT7k7TlrdTn/oykA4G/AUPzCJzmbfin7c7UD74NcH0ezwEkfQ34V+DKVHSJpAm2z2507P4mWsItJM1m9SXg/aloCnCu7aXd39W6JP3O9qcq+ieXyWMeA0kfJWt5bwycDbwD+I7tyTnEvp+sJToEmApMB960/ZkcYj8C7GH7tXS8BnBPzB1Rf5GEQ9OStIHtZyr6J5ex/Ze865QnSQ/Y3lnSV4HV0rjlXF7OSb/4drX9RjoeTDY6oq3fzixCzB3RQiTtKWmKpMclzZf0pKT5RderUWw/k3a/Yvsv5RvwlTzqIGlzSX+U9JykZyVdneMUlpK0B9mDyGtTWUdOsS8A7pV0iqRTyF7XPi+n2P1KtIRbiKTHyOYtuJ/lUzpi+/nCKpWDUouwouyRnLojpgE/By5NRUcAX7X97hxiv49sVMZU26en5H98Xm/rSdqZsoehth/MI25/E0m4hUi6N4//+ZuFpC+TtXg3B/5cdmotssT02Rzq8LZkn9eUjpJG257Z6DgVMd9h+2VJXT58tL0oz/r0B5GEW4ik08j+OXolK84m9kBhlWogSWuTPZT6H7JJxUteySsZpAnlXwAuI3s4eHiq0xnQ2KQk6S5gVeBCspd0Gj5PiKRrbH9U0pOs+DBUZBPpt+1qIkWJJNxCJN3WRbHb/e2tEknvZMW31v6aQ8wnezjd8KSUhqZ9HvgkcB9woe2bGhkz5CuScGh6kg4iGyM8HHgW2BSY0+4vqZSkl3IOBc4im1hdwH/ZvrKn+2qMOZmsH/xq2683Kk6IJNxy0gsD27Fii7Ct3+mX9DCwH3Cz7Z0k7Qt81nbDVxVJCfBAYARlLzfZbviLI5J2IGsFH0g2Jvw82w9IGk42ZrfLoXt1ir03WdfLgWTjky8DrikNWQv1E2/MtRBJvwJWB/YFziWbxvK+QiuVj7dsP19aYsj2bZJ+mlPsP5ItZzSTbP6KPJ1N9uf8X7b/WSq0/TdJ32xkYNt3AHekX0L7kb09dz7ZyyqhjiIJryRJqxfwz7T32N4hPbH/jqQfA9fnEVhSR4Fv5r0oaU3gTrLXZ59lxUnHG2mjot4Ss713D+d+0+j4klYDDiJrEe9MNqdzqLN4WaOPJL1H0mzgsXS8o6S8ppIstYZeT/8kfQvYIKfYT0g6Q9KonOKVOwR4nWyM9A1kw9UOyin29ZI+mFOsFUgaKWmSpNnp5Zz5eb2cI+l3ZBPb7wecA2xh+6t5xO5voiXcd2cCHyJb4QLbD6dB9Xm4RtI6ZMOjHiAbQnRuTrF3JHtR4dw0h8X5wGW2G7oCb/rn8DW29yXrDsi7NTYNuCp957dYPlQrj3+WXwB8m+zv3L5k/cN5NZzOA45s13lJmkk8mOuj0gsTWnGxzVwG71fUY1VgcB5jR7uIvTfwW2AdYBLwXdvzGhjvFuDjBX3XJ8la4jOd8/8sZdNozizN2VAqyyH26mTLaW1ie7ykkcDWtq9pdOz+JlrCffe0pPcAVra6w9do8AKIkj7ewzkaOVSpLE5plMDnyUYK/Bi4hGyWr+tYvghnI7wKzJQ0hbK+4Jxe330amJV3Ak4Wpxb4E5KOBRYCa+YU+wKy1+Pfk44XAlcAkYTrLJJw3/0b8DNgQ7K/mDeRTTjeSD31f5rlc7420hPAbcAZtv9UVj4ph+6YK8nnO3ZlPnC7pOtZ8S3FPOY2/hrZaJjjgO+S9c+OyyEuZH3Ah0s6EsD265KUU+x+JbojQlUkrWn71aLrkTdJ3+6q3PZ38q5LniT9iWze6qlpOs0tyBZX3a3gqrWdSMJ9JOmsLopfAmbYvjqH+IW8rJHmkz26i9h5rPNWOY9BKXZbzmMg6Y908X1LbB+cQx0+AHyTbIHTm4A9gaNs397o2P1NdEf03WCyZWauSMefAJ4EdpS0r+3jGxW44Jc1fkM2LO9DZKvufoYG94WXGVu2P5hsHoW8lhhaD/hP3v7Lp5Hzdfwo/fw48C6WL3B6JPCPBsYFlq3gMiTF351sRMjXbD/X6Nj9UbSE+yjNL7tnaeiOpIFky9+8l+wJesPG0ZamVSz7uSbZmmN79Xpz7bEfTK8Ml2IPIptjdvdGx+6mPnmNEihstWVJM2yP7a0sr9ihMaIl3HdDyJ5Ql4ZLrQEMtb1UUqNX/618WeN58ntZo7S45IuStgf+Drwzj8BpcvGSAWQt47z+7q5r+zxJXyt7lXd6TrHXkLS57fkAkjYj+/uWh5slfZ3sF1D5iJSYT7jOIgn33Q+BhyTdTvbPtPcBP1C2EOLNDY5delnjh2TDhyC/lzUmSBpC1k84mewX0X/nFPvHLO8jXQI8RdYlkYfCVlsme0Pw9rK35EaQLfSah8PJ/ptXLiPVlv3wRYruiJWQWqH/QtYnuiawwPadOcRdDfgy2dhck3WD/LKRM1tJOqGr4vTTjRyqVRZbZN93WdwUPI+ZzLpabfkU23/MIfZg4P+RtfzXJptJ7cw8ZjJLf9e+QtbNVvq79qvyiYRCfURLuI8kfZFs/OZGwENkDy7uIRvD2WgTgVfI5pUF+DRwEfCpBsZcK/3cGtiV9Lo22djlRj8UrIx9NVkiziN2ySeBu23PAvZVtuzPj8hmV2u0i8jmDy7/8/4N+fwrYGIXsSfS2L9r/VK0hPtIaSlwYJrtMZK2AX5gu9u32uoYe3blg7+uyhoU+07gQNuvpOO1gGttN3zejIJjL3s9vaeyBsUu8s+7sNj9Tcyi1ndvlP45KGlV24+RtdTy8ICkZaMRJL0bmJFT7PWBN8uO30xl7R57QOoLByC1hPP6F2SRf95Fxu5Xojui7xakh2N/AKZIegH4SyMDpta3gUHAnyT9NR1vSppSMwcXAfdJuiodH0q2AGW7x/4xcI+k0rjwTwLfzyn2Liz/8wbYBJhb+vvQ4HmOi4zdr0R3RA3SbGJrAzfYfrO362uI0+MyNrYb+kugrB47kz0UBLjT9oN5xG2C2KNY3ud/q+3ZOcUt7M+9Wf7O9QeRhEMIoUDRJxxCCAWKJBxC6FcknS/pWUmzujkvSWdJmifpkfI3NiWNk/RE2uoyrWgk4RpIGh+xI3bEbjkXAgf0cP7DwMi0jQd+CctGxnwbeDewG/Dt8pEzKyuScG2K/MsZsSN2f4hdd+nt1p7mwDgEuMiZacA6kjYgm0Fwiu1Ftl8ge4Oxp2RelUjCIYSwog3JlrUqWZDKuiuvSb8eJ7y2OvxOBq30/esxkJEavFLDS1bfbrOVjguw0QbvYsftt12p2J2q7Y99+PDhjB49upBhNa0c26z86kDDh2/I9qN3WOnY6n6O+Cpi1/a9Z82a9Zzt9Va6AsAuA9bwy1Uu/DyPxY8C5fNrTLA9oZb4jdSvk/A7GcSZHT0Oh2yYXX93USFxAV5ZdVhhsWtJBvWJ31lY7CU1/MKv1cBlk8Hlb4stR9Y8pvhlL+WnA6v7f/WjSx5/o8a5kBeSTdhUslEqWwjsU1F+ew1xgOiOCCG0AoEGqaqtDiYDn0ujJHYHXrL9DHAj8EFJQ9IDuQ+mspr065ZwCKE1aIDoWK2juot7mWxT0qVkLdphkhaQjXgYBGD7V8B1wEeAecDrwOfTuUWSvguUJvU/tR6T3EcSDiE0P8GAgXVp5WL7yF7OGzimm3PnA+fXpSJJJOEQQvNL3RHtKJJwCKHpSapbS7jZRBIOITS/aAmHEEKB6tgn3GwiCYcQmp4EHau054jaSMIhhBYgNCBawiGEUAyBOqIlHEIIhRAwoCNawiGEUAwR3RFFkPQHsok0BgM/sz1B0tHAicCLwMPAYtvHSloP+BXZqrAAx9uemn+tQwj1JikezBXkC+l97dWA6ZKuBf4b2Bl4BbiVLBED/Aw40/bdkjYhm1hj2yIqHUKoPw2IJFyE4yR9LO1vDPwLcEdp0gxJVwBbpfP7A6OkZf9keYekNW2/Wv6BaamW8ZDNBxxCaAHRHZE/SfuQJdY9bL8u6XbgMbpv3Q4Adrf9RjfnAUiTO08AVnpC9hBC3tS2D+aauX2/NvBCSsDbALsDawB7p/k8BwKfKLv+JuCrpQNJY/KsbAihcZRawtVsraaZk/ANwEBJc4DTgGlkM9v/ALgPmAo8BbyUrj8OGJuWqJ4N/FvuNQ4hNIwGDKhqazVN2x1hezHZ0tMrkDQjjZIYCFwF/CFd/xxweK6VDCHkQ6JjUOsl2Go0bRLuwSmS9icbtnYTKQmHENqX4sFc87D99aLrEELIXyt2NVSj5ZJwCKEfauOWcHv+agkhtJnqRkZUk6glHSBprqR5kk7q4vyZkh5K2+OSXiw7t7Ts3OR6fLNoCYcQmp4EAwZWudpyj5+jDuDnwAeABWRv4k62Pbt0je1/L7v+q8BOZR/xT9tjaq5ImWgJhxBawoAOVbX1Yjdgnu35tt8ELgMO6eH6I4FL6/QVuhRJOITQ/FS37ogNgafLjheksi5CalNgM7I5akoGS5ohaZqkQ2v4RstEd0QIoSX0YXTEMEkzyo4npOkK+uoIYJLtpWVlm9peKGlz4FZJM23/eSU+e5lIwiGEptfHccLP2R7bzbmFZJOBlWyUyrpyBHBMeYHthenn/DSfzU5ATUk4uiNCCC2hTt0R04GRkjaTtApZon3bKIc0X80Q4J6ysiGSVk37w4A9gdmV9/ZVv24Jr77dZuz6u4sKiT19h88WEhdg1NxrC4s9wJ2FxQZYokGFxR7IW4XFLvq/e82kuoyOsL1E0rFk8413AOfbflTSqcAM26WEfARwme3ymRa3BX4tqZOsAXta+aiKldWvk3AIoVWobm/M2b4OuK6i7FsVx6d0cd+fgNF1qUSZSMIhhNag9nxjLpJwCKHpxQQ+IYRQsJjAJ4QQiqLWXDWjGpGEQwgtoR6jI5pRJOEQQtOLPuEQQiiUIPqEQwihOIohaiGEUBDF6IgQQiiOhNr0wVzdfrVIGiFpVh+uv1DSYfWKH0Job/Va3qjZREs4hND0hJDaszui3t9qoKRLJM2RNEnS6pK+JWm6pFmSJqiL3vXurpF0u6TTJd2XFtzbK5V3SPpRuv6RtA4UknaRdIek+yXdKGmDOn+/EEIRBAxQdVuLqXcS3hr4he1tgZeBrwDn2N7V9vbAasBHu7ivp2sG2t4NOB74diobD4wAxtjeAbhE0iDgbOAw27sA5wPfr/P3CyEURAMGVLW1mnp3Rzxte2ravxg4DnhS0n8CqwNDgUeBP1bct28P11yZft5PlngB9gd+ZXsJgO1FkrYHtgempIZ0B/BMZQUljSdL4my0wbtq+a4hhBy1Yn9vNeqdhN3F8S+AsbaflnQKMLj8AkmDe7lmcfq5tJf6CnjU9h49VjBba2oCwI7bb1tZ3xBCM5JQR4yOqMYmkkpJ8NPA3Wn/OUlrAl2NhhhcxTWVpgBfkjQQQNJQYC6wXim+pEGStlvJ7xFCaDYDBlS3tZh6t4TnAsdIOp9s7aVfkq3TNAv4O9n6Tiuw/aKk/+3pmi6cC2wFPCLpLeB/bZ+ThrydJWltsu/2U7KujRBCC5MUb8z1xvZTwDZdnPpm2iqvP6psv7tr9inbf47UJ5z6gk9IW/n1DwHv63PlQwjNr06tXEkHAD8je250ru3TKs4fBZzB8lWYz7F9bjo3juW56nu2J9ZanxgnHEJoCfV4MCepA/g58AFgATBd0uQuFuy83PaxFfcOJRuhNZbsedf96d4XaqlT63WghBD6n2wuy+q2nu0GzLM93/abwGXAIVXW4kPAFNuLUuKdAhyw0t8piSQcQmgJ6uioauvFhsDTZccLUlmlT6QXwSZJ2riP9/ZJJOEQQvPr2xtzwyTNKNvG9zHaH4ER6UWwKUDN/b49iT7hEEILUF/ehnvO9thuzi0ENi473ojlD+AAsP182eG5wA/L7t2n4t7bq61Ud6IlHEJoDVJ1W8+mAyMlbSZpFeAIYPKKYVaYc+ZgYE7avxH4oKQhkoYAH0xlNYmWcAih+Ym6DFGzvUTSsWTJswM43/ajkk4FZtieDBwn6WBgCbAIOCrdu0jSd1n+LsOpthfVWqdIwiGEFlC/15ZtXwdcV1H2rbL9bwDf6Obe88kmB6ubSMIhhOYnqhl+1pIiCYcQWkBrzhVcjX6dhDs1kFdWHVZI7FFzry0kLsDsrQ8sLPZWc28qLDbAeq/MLyz2X9cobj6pVfRWYbHrQdC2K2v06yQcQmgRpXHCbSiScAihBSj6hEMIoVBtOql7JOEQQvNTtIRDCKFY0SccQggFipZwCCEUKJY3CiGEgkgtuYhnNSIJhxBaw4AYHRFCCMWIlnAIIRQs+oSLJ+kU4FXbPyq6LiGEnMXoiBBCKEpVq2a0pKb/1SLpZEmPS7ob2DqV/auk6ZIelvR7SatLWkvSk5IGpWveUX4cQmhdFrijo6qt1TR1Epa0C9kaUGOAjwC7plNX2t7V9o5k6z8dbfsVskX3SvM0HpGua+05/EIILJvAp5qtxTR7jfcCrrL9uu2XWb4g3/aS7pI0E/gMUJqo9Vzg82n/88AFlR8oaXxpKexFi2peHiqEkJc6JWFJB0iaK2mepJO6OH+CpNmSHpF0i6RNy84tlfRQ2iZX3rsymj0Jd+dC4Fjbo4HvAIMBbE8FRkjaB+iwPavyRtsTbI+1PXbo0KH51TiEUBNLVW09kdQB/Bz4MDAKOFLSqIrLHgTG2t4BmMTyJe8B/ml7TNoOrsf3avYkfCdwqKTVJK0FHJTK1wKeSf29n6m45yLgt3TRCg4htCjVrTtiN2Ce7fm23wQuAw4pv8D2bbZfT4fTgI3q/n3KNHUStv0AcDnwMHA9y5ea/m/gXmAq8FjFbZcAQ4BLc6pmCCEPUnVbzzYEni47XpDKunM0We4pGZy6M6dJOnSlvkeFph+iZvv7wPe7OPXLbm55LzDJ9osNq1QIIWfqy8iHYZJmlB1PsD2hzxGlzwJjgb3Lije1vVDS5sCtkmba/nNfP7tc0yfhvpB0Nllfz0eKrksIoY76tuT9c7bHdnNuIbBx2fFGqWzFcNL+wMnA3rYXl8ptL0w/50u6HdgJiCRcYvurRdchhNAYrs/ws+nASEmbkSXfI4BPl18gaSfg18ABtp8tKx8CvG57saRhwJ6s+NBupbRVEg4htKv6vDFne4mkY4EbgQ7gfNuPSjoVmGF7MnAGsCZwhbKYf00jIbYFfi2pk+x52mm2Z9dap0jCIYSWUKeWMLavA66rKPtW2f7+3dz3J2B0XSpRJpJwCKH5STGfcAghFMXQ64sYrSqScAihNbTgvBDViCQcQmgJJlrCIYRQENXtwVyziSQcQmgNkYTbk3AhcQe4s5C4AFvNvamw2I9v/cHCYgO8MefOwmKvOeDVwmKL4v6+1YMlOmN0RAghFChGR4QQQnGiTziEEAqjGB0RQghFipZwCCEURUSfcAghFMWITsXoiBBCKEx0R4QQQoHiwVwIIRQmXlsOIYRCxVSWIYRQEKt9H8zVtX0v6RRJX6/D56wj6Stlx8MlTar1c0MIrcvphY3ett5IOkDSXEnzJJ3UxflVJV2ezt8raUTZuW+k8rmSPlSP71VYJ4uknlrh6wDLkrDtv9k+rOGVCiE0LWtAVVtPJHUAPwc+DIwCjpQ0quKyo4EXbG8JnAmcnu4dRbY683bAAcAv0ufVpOYkLOlkSY9LuhvYOpXdLmls2h8m6am0f5SkyZJuBW6RtKakWyQ9IGmmpEPSx54GbCHpIUlnSBohaVb6jMGSLkjXPyhp37LPvlLSDZKekFTzUtQhhOZRp5bwbsA82/NtvwlcBhxScc0hwMS0Pwl4v7Jllw8BLrO92PaTwLz0eTWpqU9Y0i5kvxnGpM96ALi/l9t2BnawvSi1hj9m+2VJw4BpkiYDJwHb2x6T4owou/8YwLZHS9oGuEnSVuncGGAnYDEwV9LZtp+u5TuGEIrn+o2O2BAozwkLgHd3d43tJZJeAtZN5dMq7t2w1grV+mBuL+Aq268DpATamym2F6V9AT+Q9D6gk+wLrd/L/e8Fzgaw/ZikvwClJHyL7ZdSXWYDm7Lif3AkjQfGAwwfPryK6oYQmkEfxgkPkzSj7HiC7QkNqFJdNGp0xBKWd3UMrjj3Wtn+Z4D1gF1sv5W6LSqv74vFZftL6eL7pT+MCQCjR48uZkb3EEKfdVbfe/qc7bHdnFsIbFx2vFEq6+qaBelf62sDz1d5b5/V2r6/EzhU0mqS1gIOSuVPAbuk/Z4eqK0NPJsS8L5kLVeAV4C1urnnLrLkTeqG2ASYu9LfIITQAoQZUNXWi+nASEmbSVqFrDu18l/wk4Fxaf8w4FbbTuVHpNETmwEjgftq/WY1JWHbDwCXAw8D15N9QYAfAV+W9CAwrIePuAQYK2km8DngsfS5zwNTJc2SdEbFPb8ABqR7LgeOsr2YEELbMvV5MGd7CXAscCMwB/id7UclnSrp4HTZecC6kuYBJ5A9o8L2o8DvgNnADcAxtpfW+t2UJfj+afTo0f7DH64uJHaHlxQSF+BNrVpY7KLXmNukwDXm1hjwWu8XNUiRa8xtseXI+3voHqjK9qN38O//cG1V126z5SY1x8tTvDEXQmgJMYFPCCEUJpY3CiGEwhjodMyiFkIIhYmWcAghFCiScAghFEbYkYRDCKEQBjqjJRxCCAVxPJgLIYRCRZ9wCCEUJvqEQwihMKW5I9pRv0/CRb1Tv0SDCokLsN4r8wuL/UaBczcA/HXb9xUWe+M5dxUWe7DeKCx2vURLOIQQClTcFESNFUk4hND0jGJ0RAghFCm6I0IIoUDxYC6EEIpi6GzT9SciCYcQml47D1Frz57uEELbsVXVVgtJQyVNkfRE+jmki2vGSLpH0qOSHpF0eNm5CyU9KemhtI3pLWYk4RBCCxBLXd1Wo5OAW2yPBG5Jx5VeBz5nezvgAOCnktYpO/8ftsek7aHeAkYSDiE0PZNPSxg4BJiY9icCh76tLvbjtp9I+38DngXWW9mAkYRDCC3Brm6r0fq2n0n7fwfW7+liSbsBqwB/Liv+fuqmOFPqfWnzlngwJ+lgYJTt04quSwihGH14MDdM0oyy4wm2J5QOJN0MvKuL+05eIZ5tSd2mdUkbAL8BxtkuvdD3DbLkvQowATgROLWnyrZEErY9GZhcdD1CCAXp2xC152yP7faj7P27OyfpH5I2sP1MSrLPdnPdO4BrgZNtTyv77FIrerGkC4Cv91bZqrojJH0uNa8flvQbSQdJulfSg5JulrR+uu4USRMl3SXpL5I+LumHkmZKukHKZq2R9FRZ+X2Stkzl3X3uUZLOSftbSJqW7v2epFdT+T6Sbpc0SdJjki6R1J5jWkLoZwx0dqqqrUaTgXFpfxxwdeUFklYBrgIusj2p4twG6afI+pNn9Raw1yQsaTvgm8B+tncEvgbcDexueyfgMuA/y27ZAtgPOBi4GLjN9mjgn8CBZde9lMrPAX6aynr63JKfAT9L9y6oOLcTcDwwCtgc2LO37xdCaA2dqKqtRqcBH5D0BLB/OkbSWEnnpms+BbwPOKqLoWiXSJoJzASGAd/rLWA13RH7AVfYfg7A9iJJo4HLU9ZfBXiy7Prrbb+VKtIB3JDKZwIjyq67tOznmWl/ox4+t2QPlj+x/C3wo7Jz99leACDpoRTv7vKbJY0HxgMMHz68528eQmgadXjoVkUMPw+8v4vyGcAX0/7FZA3Mru7fr68xV3Z0xNnAOak1+iVgcNm5xakyncBb9rL/dJ2smPTdxX5Pn1uNxWX7S+nil4ztCbbH2h47dOjQPn58CKEIprrhaa04yU81SfhW4JOS1oXsjRJgbWBhOj+uuxt7cXjZz3vSfjWfOw34RNo/YiVjhxBaSXowV83WanrtjrD9qKTvA3dIWgo8CJwCXCHpBbIkvdlKxB4i6RGy1uuRqayazz0euFjSyWRdHS+tROwQQovJozuiCFUNUbM9keVvkZS87amh7VMqjtfs7hxwhu0TK66/upvPvRC4MB0uJHt4Z0lHAFuna24Hbi+759huv1AIoaUY6vFKclNqiXHCFXYBzklDQF4EvlBsdUIIeejXLeF6sz2ihnvvAnasX21CCK0gknAIIRTEhs7ojgghhOJESziEEAq0tE3XvI8kHEJoeqX5hNtRJOEQQvOrz1zBTSmScAihJbTi23DViCQcQmh6WXdE0bVojEjCIYSWEEk4hBCK4hgd0ZaMWMKgQmIP5K1C4gL8dY3tCou95oBXC4sNsPGcuwqL/fS2exUWe7/zP1tY7HrIVtYouhaN0a+TcAihdUR3RAghFCiScAghFMQtOmF7NVZ2eaMQQsiV7aq2WkgaKmmKpCfSzyHdXLe0bJHPyWXlm6UV4+dJujytzNyjSMIhhJawdGl1W41OAm6xPRK4JR135Z+2x6Tt4LLy04EzbW8JvAAc3VvASMIhhKZnV7/V6BCWryI0keUru/cqLTSxHzCpL/dHEg4htIQ+LPQ5TNKMsm18H8Ksb/uZtP93YP1urhucPnuapENT2brAi7aXpOMFwIa9BYwHcyGEltCHVu5ztsd2d1LSzcC7ujh18orxbEndRd3U9kJJmwO3SprJSi46HEk4hNASXKfhEbb37+6cpH9I2sD2M5I2AJ7t5jMWpp/zJd0O7AT8HlhH0sDUGt6IbGHiHkV3RAih6Tm9tlzNVqPJwLi0P44uVn+XNETSqml/GLAnMNvZ0IzbgMN6ur9S0yVhSftIuqboeoQQmktnp6vaanQa8AFJTwD7p2MkjZV0brpmW2CGpIfJku5ptmencycCJ0iaR9ZHfF5vAaM7IoTQ9PKaytL288D7uyifAXwx7f8JGN3N/fOB3foSM9eWsKQRkh6TdImkOZImSVpd0gGp/AHg42XX7ybpHkkPSvqTpK1T+Z2SxpRdd7ekHSXtXTaA+kFJa+X5/UIIDZLfELXcFdEdsTXwC9vbAi8DJwD/CxwE7MKKTy0fA/ayvRPwLeAHqfw84CgASVsBg20/DHwdOMb2GGAv4J+N/jIhhDyYTle3tZoikvDTtqem/YuBscCTtp9IHdsXl127NnCFpFnAmUBpDsYrgI9KGgR8AbgwlU8FfiLpOGCdsvF6y0gaXxo/+MKiRfX+biGEBnFndVurKSIJV/6qWruHa78L3GZ7e7KW8mAA268DU8jebvkUcEkqP42s32Y1YKqkbd4W3J5ge6ztsUOGDq31u4QQcmDD0qWuams1RSThTSTtkfY/DdwMjJC0RSo7suzatVk+zu6ois85FzgLmG77BQBJW9ieaft0YDrwtiQcQmhNeUzgU4QikvBc4BhJc4AhZN0M44Fr04O58sHRPwT+R9KDVIzksH0/WZ/yBWXFx0uaJekR4C3g+sZ9jRBCXkyfXltuKUUMUVtiu3KtlRvootVq+x5gq7Kib5Z2JA0n+yVyU9n1X61vVUMITcH1e2Ou2TTdyxrVkPQ54F7gZLsVu+JDCH3VrkPUcm0J234K2L4On3MRcFHNFQohtIw6vA3XlOKNuRBC07NNZwuOfKhGJOEQQktoxRcxqhFJOITQElpx+Fk1IgmHEJqeHX3CIYRQqDZtCEcSDiE0P9ssrcOM7c0oknAIoSW068sakYRDCC0hknAIIRSlReeFqEa/TsLCDOStQmIPKPBt61VUzHcGEMX26w3WG4XF3u/8yilT8nPrFy7u/aImZvJpCUsaClwOjACeAj5VmqWx7Jp9ySYeK9kGOML2HyRdCOwNvJTOHWX7oZ5ituTcESGE/qa6aSzrMJb4JOAW2yOBW9LxijWxb7M9Jq3gsx/wOmUTiQH/UTrfWwKGSMIhhFZgWLq0s6qtRocAE9P+RODQXq4/DLg+LTSxUiIJhxCaXqk7opqtRuvbfibt/x1Yv5frjwAurSj7vqRHJJ0padXeAvbrPuEQQovo23zCwyTNKDueYHtC6UDSzay4oHDJySuEtC2p26CSNgBGAzeWFX+DLHmvAkwATgRO7amykYRDCC2gTyspP2d7bLefZO/f3TlJ/5C0ge1nUpJ9trtryda3vMr2sifdZa3oxZIuIFsBvkfRHRFCaAk5dUdMBsal/XHA1T1ceyQVXREpcSNJZP3Js3oLGEk4hND0TG4LfZ4GfEDSE8D+6RhJYyWdW7pI0ghgY+COivsvkTQTmAkMA77XW8DojgghND/D0iWNH2Nu+3ng/V2UzwC+WHb8FLBhF9ft19eYkYRDCC2gNZezr0Yk4RBC07PBne05i1pT9glLuk7SOkXXI4TQPDo7XdXWahreEpbUYXtpX+6x/ZFG1SeE0JratTuippawpBGSHpN0iaQ5kiZJWl3SU5JOl/QA8ElJH5R0j6QHJF0haU1JB0i6ouyz9pF0Tdp/StKwtH+CpFlpO74s7qyye78u6ZS0f5yk2emNlctq+X4hhOZgm84lnVVtraYeLeGtgaNtT5V0PvCVVP687Z1TMr0S2N/2a5JOBE4AfgBMkLSG7deAw4EVkqakXYDPA+8GBNwr6Q5ghVmNKpwEbGZ7cXRphNA+OgucebCR6tEn/LTtqWn/YuC9af/y9HN3YBQwVdJDZAOgN7W9BLgBOEjSQOBA3j4w+r1kb6S8ZvtVsmS+Vy/1eYRsrN5ngSWVJyWNlzRD0oxFixb15XuGEIri3F7WyF09WsKV37p0/Fr6KWCK7SO7uPcy4FhgETDD9itVxlzCir9ABpftHwi8DzgIOFnS6JTws8pl75BPABg9enTr/YmF0A+Z1kyw1ahHS3gTSXuk/U8Dd1ecnwbsKWlLAElrSNoqnbsD2Bn4Vyq6IpK7gENTP/MawMdS2T+Ad0paN81S9NH02QOAjW3fRjZxxtrAmnX4jiGEguX0xlzu6pGE5wLHSJoDDAF+WX7S9v8BRwGXSnoEuIdsJnrSqIlrgA+nn1Tc+wBwIXAfcC9wru0H04QZp6byKcBj6ZYO4OL02uCDwFm2X6zDdwwhFMnQ2dlZ1dZq6tEdscR25botI8oPbN8K7NrVzbaPJeuSKC8bUbb/E+AnXdx3FnBWFx/53i7KQggtzJjOpX0a6doy4o25EELz69t8wi2lpiScJrHYvj5VCSGE7kUSDiGEwrhtxwlHEg4hND1Hd0QIIRSrXWdRiyQcQmh+jtERIYRQGENLTlNZjaacTziEEFaQJnWvZquFpE9KelRSp6RuV2xOs0DOlTRP0kll5ZtJujeVXy5pld5iRhIOIbSA6ibvqcPDu1nAx4E7u7tAUgfwc7I3fUcBR0oalU6fDpxpe0uy2R6P7i1gJOEQQkuwO6vaaovhObbn9nLZbsA82/Ntv0k2780haZn7/YBJ6bqJZMve9yj6hEMITS+b1L1pHsxtCDxddryAbM7zdYEXy2ZtXEAXKzJX6tdJeNasWc9tseXIv9TwEcOA5+pVn4gdsds09qa1VuC1lx6/ceo1+wyr8vLBkmaUHU9IU9gCIOlm4F1d3Hey7co5zRuuXydh2+vVcr+kGba77bxvpIgdsftD7BLbB9Txs/av8SMWAhuXHW+Uyp4H1pE0MLWGS+U9ij7hEELom+nAyDQSYhXgCGCys8mMbwMOS9eN4+2rBb1NJOEQQkgkfUzSAmAP4FpJN6by4ZKuA0it3GOBG4E5wO9sP5o+4kTgBEnzyPqIz+stZr/ujqiDCb1fErEjdsRuFbavAq7qovxvwEfKjq8DruviuvlkoyeqplZcDiSEENpFdEeEEEKBIgmHEEKBIgmHEEKBIgmHEEKBIgmHEEKBIgmHEEKBIgmHEEKB/j8PJbWbQm+1fAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we can make a pretty correlation heatmap with pyplot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(corr.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(corr.columns)\n",
    "ax.set_yticklabels(corr.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important predictor would be the pdays refering to the number of days that passed by after the client was last contacted from a previous campaign. This is also because more than one contact to the client was required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.011\n",
      "Model:                            OLS   Adj. R-squared:                  0.011\n",
      "Method:                 Least Squares   F-statistic:                     490.7\n",
      "Date:                Fri, 11 Feb 2022   Prob (F-statistic):          3.79e-108\n",
      "Time:                        11:53:20   Log-Likelihood:                -12590.\n",
      "No. Observations:               45211   AIC:                         2.518e+04\n",
      "Df Residuals:                   45209   BIC:                         2.520e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1036      0.002     63.956      0.000       0.100       0.107\n",
      "pdays          0.0003    1.5e-05     22.152      0.000       0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                    19684.849   Durbin-Watson:                   1.555\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            66260.074\n",
      "Skew:                           2.347   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.625   Cond. No.                         116.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "bank['y'] = pd.factorize(bank['y'])[0]\n",
    "X = bank['pdays']\n",
    "y = bank['y']\n",
    "X = sm.add_constant(X)\n",
    "bank.mod1 = sm.OLS(y, X).fit()  ## sm.OLS(output, i.e. dependent variable, input, i.e. independent variable)\n",
    "bank.mod1_summary = bank.mod1.summary()\n",
    "print(bank.mod1_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The P value is 0  showing the variables are dependant. The Model is not acceptable to build prediction models as the R squared accuracy is at 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run a basic multiple regression and review the p-values for each variable. If any variables have p-values > 0.05, remove them because they are not statistically significant. Rerun the multiple regression until you can see which of the variables in your dataset should be combined to produce an optimal model. Then build and run your multiple regression model and test its quality. Explain how this model improves the output of the simple linear regression you ran previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  int32 \n",
      "dtypes: int32(1), int64(7), object(9)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5715</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2971</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0       58    0        0          0        0     2143        0     0        0   \n",
       "1       44    1        1          1        0       29        0     0        0   \n",
       "2       33    2        0          1        0        2        0     1        0   \n",
       "3       47    3        0          2        0     1506        0     0        0   \n",
       "4       33    4        1          2        0        1        1     0        0   \n",
       "...    ...  ...      ...        ...      ...      ...      ...   ...      ...   \n",
       "45206   51    1        0          0        0      825        1     0        1   \n",
       "45207   71    5        2          3        0     1729        1     0        1   \n",
       "45208   72    5        0          1        0     5715        1     0        1   \n",
       "45209   57    3        0          1        0      668        1     0        2   \n",
       "45210   37    2        0          1        0     2971        1     0        1   \n",
       "\n",
       "       day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "0        5      0       261         1     -1         0         0  0  \n",
       "1        5      0       151         1     -1         0         0  0  \n",
       "2        5      0        76         1     -1         0         0  0  \n",
       "3        5      0        92         1     -1         0         0  0  \n",
       "4        5      0       198         1     -1         0         0  0  \n",
       "...    ...    ...       ...       ...    ...       ...       ... ..  \n",
       "45206   17      5       977         3     -1         0         0  1  \n",
       "45207   17      5       456         2     -1         0         0  1  \n",
       "45208   17      5      1127         5    184         3         3  1  \n",
       "45209   17      5       508         4     -1         0         0  0  \n",
       "45210   17      5       361         2    188        11         2  0  \n",
       "\n",
       "[45211 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing only the factor levels array inplace of the object utilizing pandas factorize to utilize all the dataset variables \n",
    "\n",
    "bank['job'] = pd.factorize(bank['job'])[0]\n",
    "bank['marital'] = pd.factorize(bank['marital'])[0]\n",
    "bank['education'] = pd.factorize(bank['education'])[0]\n",
    "bank['default'] = pd.factorize(bank['default'])[0]\n",
    "bank['housing'] = pd.factorize(bank['housing'])[0]\n",
    "bank['loan'] = pd.factorize(bank['loan'])[0]\n",
    "bank['contact'] = pd.factorize(bank['contact'])[0]\n",
    "bank['month'] = pd.factorize(bank['month'])[0]\n",
    "bank['poutcome'] = pd.factorize(bank['poutcome'])[0]\n",
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.257\n",
      "Model:                            OLS   Adj. R-squared:                  0.257\n",
      "Method:                 Least Squares   F-statistic:                     977.0\n",
      "Date:                Fri, 11 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        12:03:58   Log-Likelihood:                -6119.4\n",
      "No. Observations:               45211   AIC:                         1.227e+04\n",
      "Df Residuals:                   45194   BIC:                         1.242e+04\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0880      0.007    -13.291      0.000      -0.101      -0.075\n",
      "x1           8.34e-05      0.000      0.643      0.520      -0.000       0.000\n",
      "x2             0.0018      0.000      4.158      0.000       0.001       0.003\n",
      "x3             0.0128      0.002      6.731      0.000       0.009       0.017\n",
      "x4            -0.0108      0.001     -7.479      0.000      -0.014      -0.008\n",
      "x5            -0.0086      0.010     -0.870      0.384      -0.028       0.011\n",
      "x6           1.67e-06   4.35e-07      3.841      0.000    8.18e-07    2.52e-06\n",
      "x7             0.0644      0.003     22.881      0.000       0.059       0.070\n",
      "x8            -0.0369      0.004    -10.308      0.000      -0.044      -0.030\n",
      "x9             0.0206      0.003      7.537      0.000       0.015       0.026\n",
      "x10           -0.0003      0.000     -1.907      0.056      -0.001    8.41e-06\n",
      "x11            0.0069      0.000     14.746      0.000       0.006       0.008\n",
      "x12            0.0005   5.08e-06     93.919      0.000       0.000       0.000\n",
      "x13           -0.0017      0.000     -3.831      0.000      -0.003      -0.001\n",
      "x14           -0.0004   1.92e-05    -20.209      0.000      -0.000      -0.000\n",
      "x15           -0.0023      0.001     -3.529      0.000      -0.004      -0.001\n",
      "x16            0.1447      0.003     51.812      0.000       0.139       0.150\n",
      "==============================================================================\n",
      "Omnibus:                    13533.288   Durbin-Watson:                   1.702\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            41628.342\n",
      "Skew:                           1.552   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.531   Cond. No.                     2.53e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.53e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# multiple regression\n",
    "X = bank.iloc[:, :-1].values\n",
    "y = bank.iloc[:, 16].values\n",
    "\n",
    "X = np.append(arr = np.ones((45211, 1)).astype(int), values = X, axis = 1) # We are building our numpy array\n",
    "\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]] # Now we combine all 16 input variables into our first iteration\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit() # Now we set up our regressor function with OLS again as before.\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.257\n",
      "Model:                            OLS   Adj. R-squared:                  0.257\n",
      "Method:                 Least Squares   F-statistic:                     1202.\n",
      "Date:                Fri, 11 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        12:06:26   Log-Likelihood:                -6121.9\n",
      "No. Observations:               45211   AIC:                         1.227e+04\n",
      "Df Residuals:                   45197   BIC:                         1.239e+04\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0896      0.004    -23.104      0.000      -0.097      -0.082\n",
      "x1             0.0018      0.000      4.169      0.000       0.001       0.003\n",
      "x2             0.0127      0.002      6.682      0.000       0.009       0.016\n",
      "x3            -0.0106      0.001     -7.491      0.000      -0.013      -0.008\n",
      "x4          1.714e-06   4.32e-07      3.966      0.000    8.67e-07    2.56e-06\n",
      "x5             0.0646      0.003     23.329      0.000       0.059       0.070\n",
      "x6            -0.0372      0.004    -10.414      0.000      -0.044      -0.030\n",
      "x7             0.0205      0.003      7.526      0.000       0.015       0.026\n",
      "x8             0.0069      0.000     14.735      0.000       0.006       0.008\n",
      "x9             0.0005   5.08e-06     93.971      0.000       0.000       0.000\n",
      "x10           -0.0018      0.000     -4.181      0.000      -0.003      -0.001\n",
      "x11           -0.0004   1.92e-05    -20.155      0.000      -0.000      -0.000\n",
      "x12           -0.0023      0.001     -3.501      0.000      -0.004      -0.001\n",
      "x13            0.1448      0.003     51.867      0.000       0.139       0.150\n",
      "==============================================================================\n",
      "Omnibus:                    13543.136   Durbin-Watson:                   1.702\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            41680.267\n",
      "Skew:                           1.553   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.533   Cond. No.                     1.09e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.09e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Removing where p-values > 0.05\n",
    "X_opt = X[:, [0, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16]] # variables having p-values > 0.05 have been removed\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit() # Now we set up our regressor function with OLS again as before.\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 25.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.2, random_state = 0) \n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "print('Model accuracy score:', round(regressor.score(X_train,y_train)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score improved from 1% to 25.87% with using mutiple regression. This improves the quality of the simple linear regression by improving the accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Transform your dependent variable from question 1 into a binary shape. Build and run a logistic regression model and explain in AT LEAST two sentences how your output improves on the simple and multiple regression. Is the logistic model better or not as good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  55.900000000000006 %\n"
     ]
    }
   ],
   "source": [
    "# The Dependant variable is already in a binary shape\n",
    "# Logistic regression Model.\n",
    "\n",
    "# Training and Test set\n",
    "dfTrain = bank[:42000]\n",
    "dfTest = bank[42000:45000]\n",
    "dfCheck = bank[45000:]\n",
    "\n",
    "# Conversion to NumPy arrays\n",
    "train_y = np.asarray(dfTrain['y']) # We store target in train_y, but as numpy array\n",
    "train_x = np.asarray(dfTrain.drop('y',1)) # We remove target from the predictors (because it's the output variable)\n",
    "test_y = np.asarray(dfTest['y']) # See the comments above\n",
    "test_x = np.asarray(dfTest.drop('y',1))\n",
    "\n",
    "# input normalization.\n",
    "means = np.mean(train_x, axis=0)\n",
    "std = np.std(train_x, axis=0)\n",
    " \n",
    "train_x = (train_x - means)/std\n",
    "test_x = (test_x - means)/std\n",
    "\n",
    "# Building the Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# Testing the Model\n",
    "accuracy = model.score(test_x, test_y)\n",
    "print(\"accuracy = \", accuracy * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to linear regression Logistic regression is much better. The model accuracy compared to multiple linear regression hass improved drastically from 25.87% to 55.900000000000006 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
